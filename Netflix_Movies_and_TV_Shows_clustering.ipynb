{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "mDgbUHAGgjLW",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vipindogra/EDA-ON-HOTEL-BOOKING-ANALYSIS/blob/main/Netflix_Movies_and_TV_Shows_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual/Team\n",
        "##### **Team Member 1 -** Vipin (vipindogra913@gmail.com)\n",
        "##### **Team Member 2 -**\n",
        "##### **Team Member 3 -**\n",
        "##### **Team Member 4 -**"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Task ***"
      ],
      "metadata": {
        "id": "PCQH1f43Yycx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this project, you are required to do\n",
        "\n",
        "Exploratory Data Analysis\n",
        "\n",
        "Understanding what type content is available in different countries\n",
        "\n",
        "Is Netflix has increasingly focusing on TV rather than movies in recent years.\n",
        "\n",
        "Clustering similar content by matching text-based features"
      ],
      "metadata": {
        "id": "nzKEfisxY8VC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attribute Information**"
      ],
      "metadata": {
        "id": "eelysba0ZCG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. show_id : Unique ID for every Movie / Tv Show\n",
        "\n",
        "2. type : Identifier - A Movie or TV Show\n",
        "\n",
        "3. title : Title of the Movie / Tv Show\n",
        "\n",
        "4. director : Director of the Movie\n",
        "\n",
        "5. cast : Actors involved in the movie / show\n",
        "\n",
        "6. country : Country where the movie / show was produced\n",
        "\n",
        "7. date_added : Date it was added on Netflix\n",
        "\n",
        "8. release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "9. rating : TV Rating of the movie / show\n",
        "\n",
        "10. duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "11. listed_in : Genere"
      ],
      "metadata": {
        "id": "lI95FaqzZtiy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awi9BwN0cvQS"
      },
      "source": [
        "### <font size=\"+2\" color='#a30762'><b><i><u>Steps</u>\n",
        "* <font size=\"+2\" color='#053c96'> <b>Importing Libraries\n",
        "* <font size=\"+2\" color='#053c96'> <b>Import Data\n",
        "* <font size=\"+2\" color='#053c96'> <b>Data Summary\n",
        "* <font size=\"+2\" color='#053c96'> <b>Data Visualization\n",
        "* <font size=\"+2\" color='#053c96'> <b>Data Cleaning ( EDA )\n",
        "* <font size=\"+2\" color='#053c96'> <b>Feature Selection\n",
        "* <font size=\"+2\" color='#053c96'> <b> Model Selection\n",
        "* <font size=\"+2\" color='#053c96'><b> Hyperparameter Tuning\n",
        "* <font size=\"+2\" color='#053c96'><b>Conclusion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -"
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "\n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "\n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "\n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "\n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "\n",
        "#for nlp\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples\n",
        "import scipy.cluster.hierarchy as sch\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "working_path = \"/content/drive/MyDrive/Colab Notebooks/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv\"\n",
        "df = pd.read_csv(working_path)"
      ],
      "metadata": {
        "id": "LU794YnlbGrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info(memory_usage = 'deep' )"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "IfijGiB2jKsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Defining *DataInfoAll*"
      ],
      "metadata": {
        "id": "Q7xKOQ1ejesk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DataInfoAll(df):\n",
        "    print(f\"Dataset Shape: {df.shape}\")\n",
        "    print(\"-\"*125)\n",
        "    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n",
        "    summary = summary.reset_index()\n",
        "    summary['Name'] = summary['index']\n",
        "    summary = summary[['Name','dtypes']]\n",
        "    summary['Missing'] = df.isnull().sum().values\n",
        "    summary['Uniques'] = df.nunique().values\n",
        "    summary['First Value'] = df.iloc[0].values\n",
        "    summary['Second Value'] = df.iloc[1].values\n",
        "    return summary"
      ],
      "metadata": {
        "id": "_a3Cp9btjwP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataInfoAll(df)"
      ],
      "metadata": {
        "id": "JHldwTRHkaE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df_duplicate = df[df.duplicated()]\n",
        "print(\"Let's print all the duplicated rows as a dataframe\")\n",
        "df_duplicate"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "NaN_Checker = pd.DataFrame({\"No Of Total Values\": df.shape[0] , \"No of NaN values\": df.isnull().sum(),\n",
        "                    \"%age of NaN values\" : round((df.isnull().sum()/ df.shape[0])*100 , 2) })\n",
        "NaN_Checker.sort_values(\"No of NaN values\" , ascending = False)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  director column has highest NaN values 30.7% data is missing\n",
        "*  cast column has 9% NaN values\n",
        "*  country , date_added , rating this columns also containing missing values\n",
        "*  Ploting the null values present in the dataset"
      ],
      "metadata": {
        "id": "g2BDWHqZkyGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_nan = df.isna()\n",
        "plot_nan.head(2)"
      ],
      "metadata": {
        "id": "v5Sw0r5plipD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure( figsize = (10 , 5))\n",
        "sns.heatmap(plot_nan)"
      ],
      "metadata": {
        "id": "tjJ5Ed-Olmoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Using barplot to check the no of NaN values present in this dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2sM0OYdSls3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# null value distribution\n",
        "null_counts = df.isnull().sum()/len(df)\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.xticks(np.arange(len(null_counts)),null_counts.index,rotation='vertical')\n",
        "plt.ylabel('fraction of rows with missing data')\n",
        "plt.bar(np.arange(len(null_counts)),null_counts)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "director and cast contains large number of null values so we will drop it"
      ],
      "metadata": {
        "id": "fLz6ofkll_Tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###   Dropping irrelevent features"
      ],
      "metadata": {
        "id": "AbPO-mbx06rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['director','cast'],axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "9btvGATL1LUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Looking NaN values on data_added"
      ],
      "metadata": {
        "id": "Vuq0JmnG1SE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_added_NaN = df[df['date_added'].isna()]\n",
        "data_added_NaN.head(2)"
      ],
      "metadata": {
        "id": "vWU_5f921gax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_added_NaN.shape"
      ],
      "metadata": {
        "id": "YJGmgAsN1xSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  There are only 10 observations which are containing NaN values in data_added column\n",
        "\n"
      ],
      "metadata": {
        "id": "fsBbXnC-13v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before dropping the NaN values from date_added the shape was {df.shape}\")\n",
        "df.dropna(subset = [ 'date_added' ], inplace = True)\n",
        "print(f\"After dropping the NaN values from date_added now the shape is {df.shape}\")"
      ],
      "metadata": {
        "id": "dj4rznTA5FBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Looking for unique values"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "Uzu3kjK45Qal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*    Unique values of type column\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['type'].unique()"
      ],
      "metadata": {
        "id": "PbQVNMy35gyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Production Growth based on type of the content & release_year"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearly_movies=df[df.type =='TV Show']['release_year'].value_counts().sort_index(ascending=False).head(15)\n",
        "yearly_shows=df[df.type =='Movie']['release_year'].value_counts().sort_index(ascending=False).head(15)\n",
        "total_content=df['release_year'].value_counts().sort_index(ascending=False).head(15)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearly_movies.head()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(font_scale=1.4)\n",
        "total_content.plot(figsize=(12, 6), linewidth=2.5, color='green',label=\"Total Content / year\")\n",
        "yearly_movies.plot(figsize=(12, 6), linewidth=2.5, color='maroon',label=\"Movies / year\",ms=3)\n",
        "yearly_shows.plot(figsize=(12, 6), linewidth=2.5, color='blue',label=\"TV Shows / year\")\n",
        "plt.xlabel(\"Years\", labelpad=15)\n",
        "plt.ylabel(\"Number\", labelpad=15)\n",
        "plt.legend()\n",
        "plt.title(\"Production Growth Yearly\", y=1.02, fontsize=22);"
      ],
      "metadata": {
        "id": "0QCV5o2r59ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### release_year"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see all unique values present in release_yea"
      ],
      "metadata": {
        "id": "t8wkUbAq6RMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['release_year'].unique()"
      ],
      "metadata": {
        "id": "Xoxm5S9-6TDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the Datatype of release_year column"
      ],
      "metadata": {
        "id": "klJTFo5b6Zqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(df['release_year'][0])"
      ],
      "metadata": {
        "id": "EDUtAVcw6bE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " value_count is on release_year"
      ],
      "metadata": {
        "id": "VB1TCVR26hGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['release_year'].value_counts().to_frame().T"
      ],
      "metadata": {
        "id": "eHwH5kQI6h-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Checking outliers on release_year column***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(df.release_year)"
      ],
      "metadata": {
        "id": "79S06Ohh8RY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   As we have seen earlier before 2014 the production growth for Movies & Tv Shows were very less ,that's why it's showing those values(release_year less than 2009) as outliers\n",
        "\n"
      ],
      "metadata": {
        "id": "5FvmpOoJ8XEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(df.release_year[0])"
      ],
      "metadata": {
        "id": "d4Yxgd948bnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replacing outliers with mean value"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "release_year_Q1 = df.release_year.quantile(0.25)\n",
        "release_year_Q3 = df.release_year.quantile(0.75)\n",
        "release_year_IQR = release_year_Q3 - release_year_Q1\n",
        "print(f'release_year_Q1 = {release_year_Q1}\\nrelease_year_Q3 = {release_year_Q3}\\nrelease_year_IQR = {release_year_IQR}')"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   we don't have have any release_year which is greater than 2018\n",
        "\n"
      ],
      "metadata": {
        "id": "lQWgFOFS82pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "release_year_outliers = df[(df.release_year < (release_year_Q1 - 1.5 * release_year_IQR)) |\n",
        "                           ( df.release_year > (release_year_Q3 + 1.5 * release_year_IQR)) ]"
      ],
      "metadata": {
        "id": "abwjr3Io89bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "release_year_outliers"
      ],
      "metadata": {
        "id": "GLOzQnv_9EVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15 percentile value is 2009\n",
        "df[\"release_year\"] = np.where(df[\"release_year\"] <2009, df.release_year.mean(),df['release_year'])"
      ],
      "metadata": {
        "id": "RrhBDpGA9PVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boxplot for release_year"
      ],
      "metadata": {
        "id": "U0gLyevK9bWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.release_year.describe()"
      ],
      "metadata": {
        "id": "IL_Elwzn9a5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(df.release_year)"
      ],
      "metadata": {
        "id": "-yHB4eK-9kzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Datatype of release_year = \",type(df.release_year.iloc[0]))\n",
        "df.release_year = df.release_year.astype(\"int64\")\n",
        "print(f\"Datatype of release_year = \",type(df.release_year.iloc[0]))"
      ],
      "metadata": {
        "id": "DLpVb03R9t60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subsetting df\n",
        "df_wordcloud = df['title']\n",
        "text = \" \".join(word for word in df_wordcloud)\n",
        "# Create stopword list:\n",
        "stopwords = set(STOPWORDS)\n",
        "# Generate a word cloud image\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
        "# Display the generated image:\n",
        "# the matplotlib way:\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "It seems like words like \"Love\", \"Man\", \"World\", \"Story\" , \"Christmas\" are very common in titles.\n",
        "\n",
        "I have suprised to see \"Christmas\" ocuured so many time . The reason maybe those movies released on the month of december, but I don't have any information about the release month of movies that's why I am not able to check my hypothesis."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting pie chart on type feature\n",
        "plt.figure(figsize=(14, 7))\n",
        "labels=['TV Show', 'Movie']\n",
        "plt.pie(df['type'].value_counts().sort_values(),labels=labels,explode=[0.01,0.01],\n",
        "        autopct='%1.2f%%', startangle=90)\n",
        "plt.title('Type of Netflix Content')\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XtPKyKG_-UJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Most of the contents are Movies\n",
        "\n",
        "*   Less than ⅓ content are Tv Shows\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CRyBfnvI-cKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duration.value_counts().to_frame().T"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def all_the_duration_in_minutes():\n",
        "  \"\"\"\n",
        "  This function will convert all the duration\n",
        "  whether it's in minutes or season format to minute\n",
        "  \"\"\"\n",
        "  # replaced all the min with null string\n",
        "  df['duration'] = df.duration.str.replace(\" min\" , \"\")\n",
        "  # this time_list will contain all the value\n",
        "  time_list =[]\n",
        "  for time in df.duration.values:\n",
        "    if \"Season\" in time:\n",
        "      #time is containing Season\n",
        "      # calling convert_seasons_to_min function to convert\n",
        "      # season to total min\n",
        "      time = convert_seasons_to_min(time)\n",
        "    else:\n",
        "      #replacing single space with \"\"\n",
        "      time = time.replace(\" \",\"\")\n",
        "    #appending time (it's not containing words like min or seasons)\n",
        "    time_list.append(time)\n",
        "\n",
        "  #converting all the time into integer format\n",
        "  time_list = [ int(Time) for Time in time_list]\n",
        "\n",
        "  #Assigning time_list to df.duration\n",
        "  df.duration = time_list"
      ],
      "metadata": {
        "id": "ao2LGnvh_Bnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duration.value_counts().to_frame().T"
      ],
      "metadata": {
        "id": "vyXcN4LP_DNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_category_wise_count = sorted(category_wise_count.items(), key=lambda x: x[1])\n",
        "sorted_category_wise_count[:4]"
      ],
      "metadata": {
        "id": "UN04fNvq_fIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies = df[df['type'] == 'Movie' ]\n",
        "df_movies.head(2)"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pointplot on top tv show ratings\n",
        "tv_ratings = df_movies.groupby(['rating'])['show_id'].count().reset_index(name = 'count').sort_values(by = 'count', ascending = False)\n",
        "fig_dims = (10,6)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "sns.pointplot(x='rating',y='count',data=tv_ratings)\n",
        "plt.title('Top Movie Ratings Based On Rating System',size='20')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h-QSdjvrALr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the contents got ratings like\n",
        "\n",
        "* TV-MA (For Mature Audiences)\n",
        "* TV-14 ( May be unsuitable for children under 14 )\n",
        "* TV-PG ( Parental Guidance Suggested )\n",
        "* NR ( Not Rated )"
      ],
      "metadata": {
        "id": "W3xeOQrbAW5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['type'].unique()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tv_show = df[df['type']== 'TV Show' ]\n",
        "df_tv_show.head(2)"
      ],
      "metadata": {
        "id": "M2YNZjkYApKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pointplot on top tv show ratings\n",
        "tv_ratings = df_tv_show.groupby(['rating'])['show_id'].count().reset_index(name = 'count').sort_values(by = 'count', ascending = False)\n",
        "fig_dims = (7,4)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "sns.pointplot(x='rating',y='count',data=tv_ratings)\n",
        "plt.title('Top TV Show Ratings Based On Rating System',size='15')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6gPODkW3As_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a count vectorizer object\n",
        "count_vectorizer = CountVectorizer()\n",
        "# fit the count vectorizer using the text data\n",
        "count_vectorizer.fit(df['description'])\n",
        "# Collect the vocabulary items used in the vectorizer\n",
        "dictionary = count_vectorizer.vocabulary_.items()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary"
      ],
      "metadata": {
        "id": "_akNTYqvBAVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_seasons_to_min(value):\n",
        "  \"\"\"\n",
        "  This function will calculate no of total mins as per season no.\n",
        "  Here our assumptions are\n",
        "    1. on average 5 episodes are there in a season.\n",
        "    2. each episode avg time is 55 mins.\n",
        "  \"\"\"\n",
        "  no_of_avg_episode = 5\n",
        "  if \"Seasons\" in value:\n",
        "    #containing more than 1 seasons\n",
        "    value = value.replace(\"Seasons\",'')\n",
        "    value = value.replace(\" \",\"\")\n",
        "    total_seasons = int(value)\n",
        "    each_season_mins = ( no_of_avg_episode * 55 )\n",
        "    total_mins = (total_seasons * each_season_mins)\n",
        "    return total_mins\n",
        "\n",
        "  elif \"Season\" in value:\n",
        "    # containing only 1 season\n",
        "    value = value.replace(\"Season\",'')\n",
        "    value = value.replace(\" \",\"\")\n",
        "    total_mins = (no_of_avg_episode * 55)\n",
        "    return total_mins"
      ],
      "metadata": {
        "id": "JNcjcAPrEQTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the function\n",
        "convert_seasons_to_min(\"4 Seasons\")"
      ],
      "metadata": {
        "id": "pxY9U5pNEfIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 Seasons\" :\n",
        "\n",
        "4 Seasons = (45) or 20 episodes\n",
        "\n",
        "Each episode avg. time is 55 mins.\n",
        "\n",
        "Total time (in minutes. ) = (5520) min\n",
        "\n",
        "= 1100 mins"
      ],
      "metadata": {
        "id": "zft5-4OhE7G_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def all_the_duration_in_minutes():\n",
        "  \"\"\"\n",
        "  This function will convert all the duration\n",
        "  whether it's in minutes or season format to minute\n",
        "  \"\"\"\n",
        "  # replaced all the min with null string\n",
        "  df['duration'] = df.duration.str.replace(\" min\" , \"\")\n",
        "  # this time_list will contain all the value\n",
        "  time_list =[]\n",
        "  for time in df.duration.values:\n",
        "    if \"Season\" in time:\n",
        "      #time is containing Season\n",
        "      # calling convert_seasons_to_min function to convert\n",
        "      # season to total min\n",
        "      time = convert_seasons_to_min(time)\n",
        "    else:\n",
        "      #replacing single space with \"\"\n",
        "      time = time.replace(\" \",\"\")\n",
        "    #appending time (it's not containing words like min or seasons)\n",
        "    time_list.append(time)\n",
        "\n",
        "  #converting all the time into integer format\n",
        "  time_list = [ int(Time) for Time in time_list]\n",
        "\n",
        "  #Assigning time_list to df.duration\n",
        "  df.duration = time_list"
      ],
      "metadata": {
        "id": "rTp8LoW-EtwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duration.value_counts().to_frame().T"
      ],
      "metadata": {
        "id": "sBFPeFb_EvYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_the_duration_in_minutes()"
      ],
      "metadata": {
        "id": "nr9FL9r_E1Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duration.value_counts().to_frame().T"
      ],
      "metadata": {
        "id": "Zh7hwuE6FD2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"darkgrid\")\n",
        "plt.figure(figsize = (8,5))\n",
        "sns.kdeplot(data = df.duration[df['type'] == 'Movie'] , shade=True)"
      ],
      "metadata": {
        "id": "f3jg-4ynFHFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis on the duration of the TV-Shows"
      ],
      "metadata": {
        "id": "JOl8oB_7FOc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['type'].value_counts()"
      ],
      "metadata": {
        "id": "e88Hm0cAFSSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"darkgrid\")\n",
        "plt.figure(figsize = (12,5))\n",
        "sns.kdeplot(data = df.duration[df['type'] == 'TV Show'] , shade=True)"
      ],
      "metadata": {
        "id": "BKkEgCcWFVn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### conclusion"
      ],
      "metadata": {
        "id": "ODzBM2tsDPhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.  Director and cast contains a large number of null values so we will drop these 2 columns .\n",
        "2. In this dataset there are two types of contents where 30.86% includes TV shows and the remaining 69.14% carries Movies.\n",
        "3. We have reached a conclusion from our analysis from the content added over years that Netflix is focusing movies and TV shows\n",
        "4.  (Fom 2016 data we get to know that Movies is increased by 80% and TV shows is increased by 73% compare)\n",
        "5. From the dataset insights we can conclude that the most number of TV Shows released in 2017 and for Movies it is 2020\n",
        "6. On Netflix USA has the largest number of contents. And most of the countries preferred to produce movies more than TV shows.\n",
        "7. Most of the movies are belonging to 3 categories\n",
        "8. TOP 3 content categories are International movies , dramas , comedies.\n",
        "9. In text analysis (NLP) I used stop words, removed punctuations , stemming & 10. TF-IDF vectorizer and other functions of NLP.\n",
        "Applied different clustering models like Kmeans, hierarchical, Agglomerative clustering, DBSCAN on data we got the best cluster arrangements.\n",
        "By applying different clustering algorithms to our dataset .we get the optimal number of cluster is equal to 3"
      ],
      "metadata": {
        "id": "aU3hPE49DWXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    }
  ]
}