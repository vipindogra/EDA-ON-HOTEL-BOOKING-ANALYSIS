{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "id1riN9m0vUs",
        "89xtkJwZ18nB",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "dJ2tPlVmpsJ0",
        "Fze-IPXLpx6K",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vipindogra/EDA-ON-HOTEL-BOOKING-ANALYSIS/blob/main/Bike_Sharing_Demand_Prediction_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  Bike Sharing Demand Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual (Vipin)vipindogra913@gmail.com\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The increased usage of private vehicles in metropolitan areas has resulted in significant rise in fuel consumption's that have adverse effect on the climate. It has led people in today's society to accept problems like road traffic as the norm. Therefore the government and organzations started adopting measures to facilitate sustainable development to address the issue. Many countries have bike sharing system, such as bike sharing system in South Korea, which started to overcome all this issues and to develop a healthy environment for citizen of Seoul to live. In that context, the Bike Share initiative was launched to tackle the public mobility problem. It provided the people with an alternative to using a sustainable mode of transport for a small distance at a minimal cost. And gave people the freedom to utilize the service by themselves. In a bike-share system, a user could lend a bike from any bike stations and return it to a bike station near the destination and since it involves the activity of pedalling the bike it has beneficial health effects. And the city-wide installation of bike stations improved the accessibility of areas by bikes. Docking stations are computerized stands for the purpose of pickup and drop off of the rental bikes. Users of public bikes can rent and return rental bikes at any docking station. Users can verify their trip details (distance, duration) and measure of bodily activities (burnt calories). With this kind of smart technology and convenience, the use of Rental bike is increasing every day.\n",
        "\n",
        "So, there is a need to manage the bike rental demand and manage the continuous and convenient service for the users. This study proposes a data mining-based approach including weather data to predict whole city public bike demand. A rule-based model is used to predict the number of rental bikes needed at each hour."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing a stable supply of rental bikes becomes a major concern, which will grow the business of bike sharing. The crucial part is the prediction of the bike count required at each hour for the stable supply of rental bikes, so it's a need of the hour to solve this problem.\n",
        "The bike-sharing rental process is highly correlated to the environmental and seasonal settings. For instance weather conditions, day of the week, season, hour of the day, etc. can affect the rental behaviors.\n",
        "Therefore, the proposed model will predict the demand for rental bikes given information about the weather and time of the day."
      ],
      "metadata": {
        "id": "s6-f2Ir7ZaUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime as dt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn import tree\n",
        "from IPython.display import SVG\n",
        "from graphviz import Source\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "dataset= pd.read_csv ('/content/drive/MyDrive/Colab Notebooks/SeoulBikeData.csv',sep=',',encoding='latin')"
      ],
      "metadata": {
        "id": "ocgXEYygZ8d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f'We have total {dataset.shape[0]}  rows')\n",
        "print(f'We have total {dataset.shape[1]}  columns')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zi_KM-FubRx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have good amount of catagorical and numerical features(mostly numerical features) in our dataset"
      ],
      "metadata": {
        "id": "lJe2DtRijFdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f\"we have {dataset.duplicated().sum()} duplicate values\")"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Luckily we don't have any duplicate values in our dataset,Which is a very good thing"
      ],
      "metadata": {
        "id": "6HwtEdBpbYYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Well we don't have any missing values so there is no point of visualizing missing values because it will not show anything\n",
        "#Still I am adding the code to visualize the missing value\n",
        "'''plt.figure(figsize=(15, 5))\n",
        "sns.heatmap(dataset.isnull(), cbar=True, yticklabels=False)\n",
        "plt.xlabel(\"Column_Name\", size=14, weight=\"bold\")\n",
        "plt.title(\"Places of missing values in column\",fontweight=\"bold\",size=17)\n",
        "plt.show()'''"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Till now we know that the dataset contains the number of bikes rented per hour and date information.\n",
        "\n",
        ". It contains 8760 rows and 14 columns where the columns contains diffrent columns(features) such as:-\n",
        "\n",
        ". Date\n",
        "\n",
        ". count of bike rented\n",
        "\n",
        ". time in hours\n",
        "\n",
        ". Weather conditions(Temperature, Humidity, seasons, etc) we don't have any missing as well as duplicate values in our dataset\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "dataset.describe().transpose()\n",
        "#I am using transpose method for better view."
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date - Date on which bikes are rented\n",
        "\n",
        "Rented Bike count - Count of bikes rented at each hour\n",
        "\n",
        "Hour - For how many Hour of the day bike was rented (0-23)\n",
        "\n",
        "Temperature - Temperature of that day\n",
        "\n",
        "Humidity - Humidity measure\n",
        "\n",
        "Windspeed - Windspeed\n",
        "\n",
        "Visibility - Visibility measure\n",
        "\n",
        "Dew Point Temperature - Dew Point Temperature Measure\n",
        "\n",
        "Solar Radiation - Solar Radiation Measure\n",
        "\n",
        "Rainfall - Rainfall in mm\n",
        "\n",
        "Snowfall - Snowfall measure\n",
        "\n",
        "Seasons - what season it was when bike was rented\n",
        "\n",
        "1. spring item\n",
        "2. summer item\n",
        "3. fall\n",
        "4. winter\n",
        "\n",
        "Holiday - Whether a holiday or not\n",
        "\n",
        "Functional Day - Whether a functional day or not"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in dataset.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",dataset[i].nunique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting date variable in to datetime datatype\n",
        "dataset['Date'] = dataset['Date'].apply(lambda x: dt.strptime(x,'%d/%m/%Y'))"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of days for which the data is collected\n",
        "print('Number of days the data is collected: ',dataset['Date'].max()-dataset['Date'].min())"
      ],
      "metadata": {
        "id": "K4LDGR8nczuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Days between which the data is collected\n",
        "print('Start date: ',dataset['Date'].min())\n",
        "print('End date: ',dataset['Date'].max())"
      ],
      "metadata": {
        "id": "pCbLWh9ic3FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ". The dataset is from a rental bike company based out of Seoul. The goal of this project is to develop a machine learning model that can predict the demand for rental bikes.\n",
        "\n",
        ". The dataset contains the hourly weather conditions for a period of 364 days, and other details such as whether a said day was a holiday or not.\n",
        "\n",
        ". The dataset containes a total of 8870 records and 14 attributes. There are no duplicate records or missing values in the dataset."
      ],
      "metadata": {
        "id": "taUPuGHVc7UI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will rename the Features so that we can iterate without any problem of missing space while execution of cod"
      ],
      "metadata": {
        "id": "LYW9DE6gdEfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the columns\n",
        "dataset.rename(columns= {'Date':'date','Rented Bike Count': 'rented_bike_count', 'Hour':'hour',\n",
        "                    'Temperature(°C)':'temperature', 'Humidity(%)':'humidity',\n",
        "                    'Wind speed (m/s)': 'wind_speed', 'Visibility (10m)': 'visibility',\n",
        "                    'Dew point temperature(°C)':'dew_point_temp',\n",
        "                    'Solar Radiation (MJ/m2)': 'solar_radiation', 'Rainfall(mm)': 'rainfall',\n",
        "                    'Snowfall (cm)':'snowfall', 'Seasons':'seasons',\n",
        "                    'Holiday':'holiday', 'Functioning Day':'func_day'},\n",
        "          inplace=True)"
      ],
      "metadata": {
        "id": "OuekhfLxdJYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "id": "HUY36p4ddNAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Engineering new features 'month' and 'day_of_week' from the 'date':\n",
        "#add month, day_of_week columns\n",
        "for df in [dataset]:\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['day_of_week'] = df['date'].dt.dayofweek\n",
        "\n",
        "# {0:'Monday',1:'Tuesday',2:'Wednesday',3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}"
      ],
      "metadata": {
        "id": "H23PSZ0edOi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a city, it is highly likely that the rental bike demand may follow different pattern over the weekends when people do not generally go to work.\n",
        "\n",
        "To capture this trend, we can define a new feature 'weekend' which indicates whether a said day is a weekend (1) or not (0)."
      ],
      "metadata": {
        "id": "Z-yEk-M4fcQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# engineering new feature 'weekend' from day_of_week\n",
        "dataset['weekend'] = dataset['day_of_week'].apply(lambda x: 1 if x>4 else 0)"
      ],
      "metadata": {
        "id": "ggP8gKfDfmgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ". We had zero null values in our dataset\n",
        "\n",
        ". Zero duplicate values found.\n",
        "\n",
        ".We changed the data type of Date Column from 'object' to 'datetime64[ns]'. This was done for featurin engineering.\n",
        "\n",
        ". We created two new columns with the help of 'Date' column 'Month' & 'Day' which would further use for EDA and later we drop the Date column."
      ],
      "metadata": {
        "id": "9a60Y2RlfuH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Chart - Analyzing the distribution of the dependent variable:\n",
        "\n",
        "# defining dependent variable separately\n",
        "dependent_variable = ['rented_bike_count']\n",
        "\n",
        "# visualizing the distribution of the dependent variable - rental bike count\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.distplot(df[dependent_variable])\n",
        "plt.xlabel(dependent_variable[0])\n",
        "plt.title(dependent_variable[0]+' distribution')\n",
        "plt.axvline(df[dependent_variable[0]].mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "plt.axvline(df[dependent_variable[0]].median(), color='cyan', linestyle='dashed', linewidth=2)"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# skew of the dependent variable\n",
        "df[dependent_variable].skew()"
      ],
      "metadata": {
        "id": "ym9GuStjgGja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the skewness of the dependent variable"
      ],
      "metadata": {
        "id": "bDKvwnpygOvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   \n",
        "The dependent variable is positively skewed. To get better predictions, it is ideal if the dependent variable is almost normally distributed.\n",
        "\n",
        "*   To achieve this, we can transform the data by log, sqrt, etc.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not a negative, we can fix it to get the better predications by transform the data by log, sqrt."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Chart - 2 Log transformation & Square-root transformation:\n",
        "# visualizing the distribution of dependent variable after log transformation\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(np.log1p(df[dependent_variable]))\n",
        "plt.xlabel(dependent_variable[0])\n",
        "plt.title(dependent_variable[0]+' distribution')\n",
        "plt.axvline(np.log1p(df['rented_bike_count']).mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "plt.axvline(np.log1p(df['rented_bike_count']).median(), color='cyan', linestyle='dashed', linewidth=2)"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# skew of the dependent variable after log transformation\n",
        "np.log1p(df[dependent_variable]).skew()"
      ],
      "metadata": {
        "id": "cygxkmsVg2q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the dependent variable is skewed, lets try to reduce the skewness by appling square root method"
      ],
      "metadata": {
        "id": "NogWHfNkg9Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the distribution of dependent variable after sqrt transformation\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(np.sqrt(df[dependent_variable]))\n",
        "plt.xlabel(dependent_variable[0])\n",
        "plt.title(dependent_variable[0]+' distribution')\n",
        "plt.axvline(np.sqrt(df['rented_bike_count']).mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "plt.axvline(np.sqrt(df['rented_bike_count']).median(), color='cyan', linestyle='dashed', linewidth=2)"
      ],
      "metadata": {
        "id": "IkEQea3Rg-K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # skew of the dependent variable after sqrt transformation\n",
        "np.sqrt(df[dependent_variable]).skew()"
      ],
      "metadata": {
        "id": "d6q8LCnehB7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bingo.......! the skewness has decresed, earlier it was negative left skewed but it seem good now"
      ],
      "metadata": {
        "id": "mqq-tUkbhHE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are trying to reduce the skewness over here with the help of log transformation or square root tranformation."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We were able to reduce skewness on square root transformation. Hence we can use square root transformation during the modelling."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We were able to reduce skewness on square root transformation. Hence we can use square root transformation during the modelling"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 Analyzing the distribution of continuous independent variables:\n",
        "# defining continuous independent variables separately\n",
        "continuous_var = ['temperature', 'humidity', 'wind_speed', 'visibility', 'solar_radiation', 'rainfall', 'snowfall']\n",
        "\n",
        "# Analyzing the distribution of the continuous independent variables\n",
        "for col in continuous_var:\n",
        "  plt.figure(figsize=(9,4))\n",
        "  sns.distplot(df[col])\n",
        "  plt.axvline(df[col].mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "  plt.axvline(df[col].median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "  plt.title(col+' distribution')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Analyze The distribution of continous independent variable."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normally distributed attributes: temperature, humidity.\n",
        "\n",
        "Positively skewed attributes: wind, solar_radiation, snowfall, rainfall.\n",
        "\n",
        "Negatively skewed attributes: visibility."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Yes, it goona be very helpful in modeling."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chart -4 : Analyzing the relationship between dependent variable and continuous independent variables:\n",
        "# Analyzing the relationship between the dependent variable and the continuous variables\n",
        "for i in continuous_var:\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.scatter(x=i,y=dependent_variable[0],data=df)\n",
        "  plt.xlabel(i)\n",
        "  plt.ylabel(dependent_variable[0])\n",
        "  plt.title(i+' vs '+ dependent_variable[0])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart will show the relation between the dependent and continous independent variables."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positively correlated variables: temperature, windspeed, visibility, solar radiation. Negatively correlated variables: humidity, rainfall, snowfall."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It will help us to identify the positive and negative corelation between the variables."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 to 10"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  #Chart 5 - Analyzing the relationship between dependent variable and categorical independent variables:\n",
        "  plt.figure(figsize=(10,5))\n",
        "  sns.barplot(x=dataset['hour'],y=dependent_variable[0],data=df)\n",
        "  plt.xlabel(\"Hours \")\n",
        "  plt.ylabel(\"Rentel Bike count\")\n",
        "  plt.title('Hour vs Rentel_bike')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Instead of writing same code for all categoriacl features We can use for loop so that we can save time and space while executing the project"
      ],
      "metadata": {
        "id": "k7SpH6iXixU4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ij5qcxy7i8J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### there are 5 charts within the same code so there are total 10 charts so far"
      ],
      "metadata": {
        "id": "_aRDzSuJjIOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chart  - Analyzing the relationship between dependent variable and categorical independent variables:\n",
        "# defining categorical independent variables separately\n",
        "categorical_var = ['hour','seasons', 'holiday', 'func_day', 'month', 'day_of_week', 'weekend']"
      ],
      "metadata": {
        "id": "OjreuAZljQRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyzing the relationship between the dependent variable and the categorical variables\n",
        "for i in categorical_var:\n",
        "  plt.figure(figsize=(10,5))\n",
        "  sns.barplot(x=i,y=dependent_variable[0],data=df)\n",
        "  plt.xlabel(i)\n",
        "  plt.ylabel(dependent_variable[0])\n",
        "  plt.title(i+' vs '+ dependent_variable[0])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "-kMZ19N1jW5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Highest rented bike count on a functioning day vs a non functioning day\n",
        "dataset.groupby(['func_day'])['rented_bike_count'].max()"
      ],
      "metadata": {
        "id": "SjL2HXuhjasf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Non functioning days in the dataset\n",
        "df[(dataset['func_day']=='No')]['date'].unique()"
      ],
      "metadata": {
        "id": "-LlyzUM8jg_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "hvVeOVn7jorz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In these chart, it will show us the all the isights of the dependent variable with cateogrical independent variables."
      ],
      "metadata": {
        "id": "eZnffg2Wjq9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "mupxvyaljwCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The number of bikes rented is on average higher during the rush hours.\n",
        "\n",
        "2. The rented bike counts is higher during the summer and lowest during the winter.\n",
        "\n",
        "3. The rented bike count is higher on working days than on non working days.\n",
        "4. On a non functioning day, no bikes are rented in all the instances of the data.\n",
        "\n",
        "5. The number of bikes rented on average remains constant throughout Monday - Saturday, it dips on Sunday, and on average, the rented bike counts is lower on weenends than on weekdays."
      ],
      "metadata": {
        "id": "b7goaMzdj0Gt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 Bike demand throughout the day:"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in categorical_var:\n",
        "  if i == 'hour':\n",
        "    continue\n",
        "  else:\n",
        "    fig, ax = plt.subplots(figsize=(10,5))\n",
        "    sns.pointplot(data=df, x='hour', y='rented_bike_count', hue=i, ax=ax)\n",
        "    plt.title('Hourly bike demand broken down based on the attribute: '+i)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left',title=i)\n",
        "    plt.show"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the Point plot, so that these plots can show us the at what time, what day and in what season bike is required the most."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ". In winters the overall demand for rented bikes is comparitively lower than that of other seasons.\n",
        "\n",
        ". On a non functioning day, no bikes are rented.\n",
        "\n",
        ". The demand for rented bikes throughout the day on holidays and weekends follow a different pattern than other days. On regular days, the demand for the bikes is higher during rush hours. On holidays or weekends, the demand is comparitively lower in the mornings, and is higher in the afternoons"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the help of this insight its very clear about the demand of the bike, so it gonna be very helpful"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 Outlier analysis:"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in categorical_var:\n",
        "  plt.figure(figsize=(10,5))\n",
        "  sns.boxplot(x = col,y = dependent_variable[0],data=df)\n",
        "  plt.title(col+' boxplot')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the box-plot to identify the outliers in the data, they will show us very clearly in this."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are outliers in the data and this must be taken into consideration in the model building phase."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its shows that there are outliers in the data and it will be taking into the consedration now at the time of model building."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart visualization code For Bike demand Throughout the Day in terms of diffrent attributes\n",
        "for i in categorical_var:\n",
        "  if i == 'hour':\n",
        "    continue\n",
        "  else:\n",
        "    fig, ax = plt.subplots(figsize=(10,5))\n",
        "    sns.pointplot(data=df, x='hour', y='rented_bike_count', hue=i, ax=ax)\n",
        "    plt.title('Hourly bike demand broken down based on the attribute: '+i)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left',title=i)\n",
        "    plt.show"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the Point plot, so that these plots can show us the at what time, what day and in what season bike is required the most."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In winters the overall demand for rented bikes is comparitively lower than that of other seasons.\n",
        "\n",
        "On a non functioning day, no bikes are rented.\n",
        "\n",
        "The demand for rented bikes throughout the day on holidays and weekends follow a different pattern than other days. On regular days, the demand for the bikes is higher during rush hours. On holidays or weekends, the demand is comparitively lower in the mornings, and is higher in the afternoons"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the help of this insight its very clear about the demand of the bike, so it gonna be very helpful"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        " ## Correlation magnitude for continuous variables\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title('Correlation Analysis')\n",
        "correlation = df[continuous_var+dependent_variable].corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above graph, we can see that Temperature and Dew_point_temperature is highy correlated, keeping the factor of 0.91 . And, then we have hour in the graph which is having good correlation with our dependent variable."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here is no multicollinerity in the data."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(dataset)"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets see our features again\n",
        "df.columns"
      ],
      "metadata": {
        "id": "GkoRrpvsnWjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there are vaey few day on which there was snowfall / rainfall, it is in our interest that we convert these columns to binary categorical columns indicating whether there was rainfall / snowfall at that particular hour"
      ],
      "metadata": {
        "id": "8hX4IwmHndEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting snowfall and rainfall to categorical attributes\n",
        "df['snowfall'] = df['snowfall'].apply(lambda x: 1 if x>0 else 0)\n",
        "df['rainfall'] = df['rainfall'].apply(lambda x: 1 if x>0 else 0)"
      ],
      "metadata": {
        "id": "_8ZX9sIsneF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When\n",
        "\n",
        "Visibility >= 20 Km ---> Clear (high visibility)\n",
        "\n",
        "4 Km <= Visibility < 10 Km ---> Haze (medium visibility)\n",
        "\n",
        "Visibility < 4 Km ---> Fog (low visibility)\n",
        "\n",
        "Converting visibility based on the above mentioned threshold values. Since they are ordinal, we can encode them as 0 (low visibility), 1 (medium visibility), 2 (high visibility)"
      ],
      "metadata": {
        "id": "QVrpnL-4nkLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the visibility column\n",
        "dataset['visibility'] = pd.cut(df.visibility,bins=[0,399,999,2001],labels=[0,1,2])"
      ],
      "metadata": {
        "id": "8w7J6Kj5n10e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nominal categorical features 'month', 'day_of_week', 'hour' are nominal categorical variables. Hence we need to encode them."
      ],
      "metadata": {
        "id": "3CdkjknSn60v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding\n",
        "df = pd.get_dummies(df, columns = ['month', 'hour','day_of_week'])"
      ],
      "metadata": {
        "id": "jVuUk0tgn74Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "_5uydTSQn_Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# NO MISSING VALUES ARE THERE IN OUR DATA SET SO WE WILL SKIP THIS PART"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "sns.set(font_scale=1.0)\n",
        "fig, axes = plt.subplots(nrows=4,ncols=2)\n",
        "fig.set_size_inches(15, 15)\n",
        "sns.boxplot(data=dataset,y=\"rented_bike_count\",x=\"humidity\",orient=\"v\",ax=axes[0][0])\n",
        "sns.boxplot(data=dataset,y=\"rented_bike_count\",x=\"hour\",orient=\"v\",ax=axes[0][0])\n",
        "sns.boxplot(data=dataset,y=\"rented_bike_count\",x=\"temperature\",orient=\"v\",ax=axes[1][0])\n",
        "sns.boxplot(data=dataset,y=\"rented_bike_count\",x=\"wind_speed\",orient=\"v\",ax=axes[1][1])\n",
        "sns.boxplot(data=dataset,y=\"rented_bike_count\",x=\"visibility\",orient=\"v\",ax=axes[2][0])\n",
        "sns.boxplot(data=dataset,y=\"rented_bike_count\",x=\"seasons\",orient=\"v\",ax=axes[2][1])\n",
        "sns.boxplot(data=dataset,y=\"rented_bike_count\",x=\"holiday\",orient=\"v\",ax=axes[3][0])\n",
        "sns.boxplot(data=dataset,y=\"rented_bike_count\",x=\"solar_radiation\",orient=\"v\",ax=axes[3][1])"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have encoded the 'month' and 'day_of_week' attributes, we no longer need 'weekend' and 'seasons' attributes since they essentially convey similar information."
      ],
      "metadata": {
        "id": "lI0FcfH2ogxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping seasons and weekend\n",
        "dataset.drop(['seasons','weekend'],axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Nv1X-PDSokoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "axsbYT09onud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding the data to fit a model:\n",
        "\n",
        "# encoding\n",
        "dataset['func_day'] = np.where(dataset['func_day'] == 'Yes',1,0)\n",
        "dataset['holiday'] = np.where(dataset['holiday'] == 'Holiday', 1,0)"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping date attribute\n",
        "dataset.drop('date',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "Z5X_XvGmovuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The date column cannot be used to build a ML model. Hence we can drop it."
      ],
      "metadata": {
        "id": "92N4mIGyozpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining dependent and independent variables\n",
        "X = dataset.drop('rented_bike_count',axis=1)\n",
        "y = np.sqrt(df[dependent_variable])"
      ],
      "metadata": {
        "id": "vIcGguruo0pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of dataframe\n",
        "df.shape"
      ],
      "metadata": {
        "id": "VtA2ADo7o3-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metric"
      ],
      "metadata": {
        "id": "Q3zg22SspkFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        ". We know that the data we are working with contains outliers, we didnt drop them because if we do so, we may loose out important trends/patterns in the data.\n",
        "\n",
        ". Decision Trees or any tree based algorithms that we will use here are known to handle outliers. Hence we can use RMSE as the evaluation metric.\n",
        "\n",
        ".Since RMSE penalizes outliers a lot, this is a good metric to check whether ot not the model has learnt all the trends/patterns in the data.\n",
        "\n",
        ".In addition to RMSE, we can use R2 score to make the results more explainable to a larger audience."
      ],
      "metadata": {
        "id": "9Fdp0HrOpp7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining rmse evaluation metric\n",
        "def rmse(actual,predicted):\n",
        "  '''\n",
        "  rmse(actual_y,predicted_y)\n",
        "  '''\n",
        "  mse = mean_squared_error(actual,predicted)\n",
        "  rmse = np.sqrt(mse)\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "khdhCiI4p02T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 Decisison tree"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "# Using gridsearchcv to find the hyperparameters with best predictions\n",
        "# A full grown tree has a max depth of 28.\n",
        "dt_model = DecisionTreeRegressor(random_state=0)\n",
        "dt_params = {'max_depth':np.arange(20,26),\n",
        "             'min_samples_leaf':np.arange(30,41,2)\n",
        "             }"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting model with hypertuned paramaters using grid search\n",
        "dt_gridsearch = GridSearchCV(dt_model,dt_params, cv=6, scoring= 'neg_root_mean_squared_error')\n",
        "dt_gridsearch.fit(X_train,y_train)\n",
        "dt_best_params = dt_gridsearch.best_params_\n",
        "\n",
        "# model best parameters\n",
        "dt_best_params"
      ],
      "metadata": {
        "id": "w_it6nmKqDIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building DT model with best parameters\n",
        "dt_model = DecisionTreeRegressor(max_depth=dt_best_params['max_depth'], min_samples_leaf=dt_best_params['min_samples_leaf'], random_state=0)"
      ],
      "metadata": {
        "id": "P3YNFl3pqKp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting model\n",
        "dt_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "3JRoXtu2qOGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dt train predictions\n",
        "dt_y_train_pred = dt_model.predict(X_train)"
      ],
      "metadata": {
        "id": "a0mpjvm3qUMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dt test predictions\n",
        "dt_y_test_pred = dt_model.predict(X_test)"
      ],
      "metadata": {
        "id": "TzcdTI5MqX6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "FioMR3YSqcxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train score\n",
        "dt_train_r2_score = r2_score(np.square(y_train),np.square(dt_y_train_pred))\n",
        "dt_train_r2_score\n",
        "\n",
        "# test score\n",
        "dt_test_r2_score = r2_score(np.square(y_test),np.square(dt_y_test_pred))\n",
        "dt_test_r2_score"
      ],
      "metadata": {
        "id": "0Oa-wCgkqiPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training rmse\n",
        "dt_train_rmse = rmse(np.square(y_train),np.square(dt_y_train_pred))\n",
        "dt_train_rmse\n",
        "\n",
        "# test rmse\n",
        "dt_test_rmse = rmse(np.square(y_test),np.square(dt_y_test_pred))\n",
        "dt_test_rmse"
      ],
      "metadata": {
        "id": "hKRmldtSqlrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Decision tree is low bias, high variance model. If we fit a decision tree model on a dataset without tuning the hyperparameters, we get zero RMSE for training data and high RMSE for test data. Also the R2 score is 1 for train data, and is significantly low when that model is fit on test data. Our aim is to build a generalized model, that is able to predict the dependent variable for unseen data with less error. To achieve this, we can tune the decision tree hyperparameters, thereby reducing the model complexity, which in turn improve predictions for the test data"
      ],
      "metadata": {
        "id": "qBgmaL5tqvhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicted vs actual values of dependent variable\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.scatter(x=np.square(y_test),y=np.square(dt_y_test_pred))\n",
        "plt.xlabel('Actual Rented Bike Count')\n",
        "plt.ylabel('Predicted Rented Bike Count')\n",
        "plt.title('Actual vs Predicted values of dependent variable using: DECISION TREE')"
      ],
      "metadata": {
        "id": "z6uqjad4q0OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision tree diagram\n",
        "graph = Source(tree.export_graphviz(dt_model,\n",
        "                                    out_file=None,\n",
        "                                    feature_names=X_train.columns,\n",
        "                                    filled= True))\n",
        "display(SVG(graph.pipe(format='svg')))"
      ],
      "metadata": {
        "id": "VYuOhzaXq2MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importances\n",
        "\n",
        "dt_feat_imp = pd.Series(dt_model.feature_importances_, index=X.columns)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title('Feature Importances: DECISION TREE')\n",
        "plt.xlabel('Relative Importance')\n",
        "dt_feat_imp.nlargest(20).plot(kind='barh')"
      ],
      "metadata": {
        "id": "xIn5gSxJq6eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random forest model\n",
        "rf_model = RandomForestRegressor(random_state=0)\n",
        "rf_params = {'n_estimators':[500],                    # limited due to computational power availability\n",
        "             'min_samples_leaf':np.arange(25,31)}     # Approximate range after fitting a decision tree model"
      ],
      "metadata": {
        "id": "OtmgajA4spKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting a rf model with best parameters obtained from gridsearch\n",
        "rf_gridsearch = GridSearchCV(rf_model,rf_params,cv=6,scoring='neg_root_mean_squared_error')\n",
        "rf_gridsearch.fit(X_train,y_train)\n",
        "rf_best_params = rf_gridsearch.best_params_"
      ],
      "metadata": {
        "id": "0Vu-8KvussvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best parameters for random forests\n",
        "rf_best_params"
      ],
      "metadata": {
        "id": "80uoSzTQuBWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting RF model with best parameters\n",
        "rf_model = RandomForestRegressor(n_estimators=rf_best_params['n_estimators'],\n",
        "                                 min_samples_leaf=rf_best_params['min_samples_leaf'],\n",
        "                                 random_state=0)"
      ],
      "metadata": {
        "id": "oA2_ivYIuEv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit\n",
        "rf_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "2XK8fPIhuF_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rf predictions on train data\n",
        "rf_y_train_pred = rf_model.predict(X_train)"
      ],
      "metadata": {
        "id": "iPt_UyGvuJKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rf predictions on test data\n",
        "rf_y_test_pred = rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "aoomJkfYuPF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train score\n",
        "rf_train_r2_score = r2_score(np.square(y_train),np.square(rf_y_train_pred))\n",
        "rf_train_r2_score"
      ],
      "metadata": {
        "id": "mCYNRb0UuR5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test score\n",
        "rf_test_r2_score = r2_score(np.square(y_test),np.square(rf_y_test_pred))\n",
        "rf_test_r2_score"
      ],
      "metadata": {
        "id": "hYnsK4KluVON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train rmse\n",
        "rf_train_rmse = rmse(np.square(y_train),np.square(rf_y_train_pred))\n",
        "rf_train_rmse"
      ],
      "metadata": {
        "id": "HjY3CmL4uZHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test rmse\n",
        "rf_test_rmse = rmse(np.square(y_test),np.square(rf_y_test_pred))\n",
        "rf_test_rmse"
      ],
      "metadata": {
        "id": "9WxDpRUIuc4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importances\n",
        "\n",
        "rf_feat_imp = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title('Feature Importances: RANDOM FORESTS')\n",
        "plt.xlabel('Relative Importance')\n",
        "rf_feat_imp.nlargest(20).plot(kind='barh')"
      ],
      "metadata": {
        "id": "oMQLtNdzugaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature is the most important feature in predicting the value of the dependent variable for random forests, followed by humidity and func_day"
      ],
      "metadata": {
        "id": "UdduJuxtuoH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual vs predicted values of dependent variables\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.scatter(x=y_test,y=rf_y_test_pred)\n",
        "plt.xlabel('Actual Rented Bike Count')\n",
        "plt.ylabel('Predicted Rented Bike Count')\n",
        "plt.title('Actual vs Predicted values of dependent variable using: RANDOM FOREST')"
      ],
      "metadata": {
        "id": "R1SFQSK1upcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Scatter plot of the actual and predicted values of the dependent variable on test data using random forests."
      ],
      "metadata": {
        "id": "EP0xgwtcuvUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 Gradient Boosting"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GBM model\n",
        "gb_model = GradientBoostingRegressor(random_state=0)\n",
        "gb_params = {'n_estimators':[500],\n",
        "             'min_samples_leaf':np.arange(25,31)}"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding best parameters\n",
        "gb_gridsearch = GridSearchCV(gb_model,gb_params,cv=6,scoring='neg_root_mean_squared_error')\n",
        "gb_gridsearch.fit(X_train,y_train)\n",
        "gb_best_params = gb_gridsearch.best_params_"
      ],
      "metadata": {
        "id": "zt0GAQtvvHuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GBM best parameters\n",
        "gb_best_params"
      ],
      "metadata": {
        "id": "XZNXJbTev3Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building GBM model with best parameters\n",
        "gb_model = GradientBoostingRegressor(n_estimators=gb_best_params['n_estimators'],\n",
        "                                     min_samples_leaf=gb_best_params['min_samples_leaf'],\n",
        "                                     random_state=0)"
      ],
      "metadata": {
        "id": "4h_nHlS3v7nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit\n",
        "gb_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "g4Bg0dRsv_qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient boosing train predictions\n",
        "gb_y_train_pred = gb_model.predict(X_train)"
      ],
      "metadata": {
        "id": "hY7loyZMwCqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient boosting test predictions\n",
        "gb_y_test_pred = gb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "QrPDd5JMwITX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train score\n",
        "gb_train_r2_score = r2_score(np.square(y_train),np.square(gb_y_train_pred))\n",
        "gb_train_r2_score"
      ],
      "metadata": {
        "id": "929XcO_WwNY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test score\n",
        "gb_test_r2_score = r2_score(np.square(y_test),np.square(gb_y_test_pred))\n",
        "gb_test_r2_score"
      ],
      "metadata": {
        "id": "S7-Fg0hlwO__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train rmse\n",
        "gb_train_rmse = rmse(np.square(y_train),np.square(gb_y_train_pred))\n",
        "gb_train_rmse"
      ],
      "metadata": {
        "id": "V_XYmMpkwT63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test rmse\n",
        "gb_test_rmse = rmse(np.square(y_test),np.square(gb_y_test_pred))\n",
        "gb_test_rmse"
      ],
      "metadata": {
        "id": "ZX2GIv3MwVWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient boosting feature importances\n",
        "gbm_feat_imp = pd.Series(gb_model.feature_importances_, index=X.columns)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title('Feature Importances: Gradient Boosting Machine (GBM)')\n",
        "plt.xlabel('Relative Importance')\n",
        "gbm_feat_imp.nlargest(20).plot(kind='barh')"
      ],
      "metadata": {
        "id": "dcaITKWfwZyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature is the most important feature in predicting the value of the dependent variable using gradient boosting, followed by func_day and humidity."
      ],
      "metadata": {
        "id": "lh_7iXARwdY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual vs predicted values of dependent variables\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.scatter(x=y_test,y=gb_y_test_pred)\n",
        "plt.xlabel('Actual Rented Bike Count')\n",
        "plt.ylabel('Predicted Rented Bike Count')\n",
        "plt.title('Actual vs Predicted values of dependent variable using: GRADIENT BOOSTING MACHINE (GBM)')"
      ],
      "metadata": {
        "id": "DwYMH-XzwjRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scatter plot of the actual and predicted values of the dependent variable on test data using Gradient boosting."
      ],
      "metadata": {
        "id": "_txA59WBwliX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   We trained 4 unique Machine Learning models using the training dataset, and the its respective performance was improved through hyperparameter tuning.\n",
        "\n",
        "*  We initially started with the decision tree model, mainly because it is easily explainable to the stakeholders, and its low training time.\n",
        "\n",
        "*   Once we were successfully able to fit a decision tree, it was necessary to improve the prediction accuracy, and reduce errors in the predictions.\n",
        "\n",
        "*   To achieve this, we fit a random forest model on the training data, and the final predictions showed less errors compared to that of decision tree model.\n",
        "\n",
        "\n",
        "*   To further improve the predictions of the model, we fit 2 boosting models namely; Gradient boosting machine (GBM) and Extreme gradient boost (XG Boost). The predictions obtained from these models showed errors in the same range, but the errors were lower than that of decision tree mode\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The XG Boost model has the lowest RMSE, and the highest R2 score.\n",
        "\n",
        "Final choice of model depends on:\n",
        "\n",
        "\n",
        "*   If it is absolutely necessary to have a model with the best accuracy, then XG boost will be the best choice, since it has the lowest RMSE than other models built.\n",
        "\n",
        "\n",
        "*  But as discussed above, higher the model complexity, lower is the model explainability. Hence if the predictions must be explained to stakeholers, then XG Boost is not an ideal choice.\n",
        "\n",
        "*   In this case decision tree can be used, since they are easier to explain. By choosing a simpler model, we will be compromising with the model accuracy (Accuracy vs Interpretability tradeoff).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wY0odyd5xwLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}